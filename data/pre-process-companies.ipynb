{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"companies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         country  founded                        id      industry  \\\n",
      "0  united states   2023.0             bedrock-black           NaN   \n",
      "2  united states   1977.0           wh-construction  construction   \n",
      "4  united states      NaN         gregory-hitchcock  construction   \n",
      "5  united states      NaN  mission-imaging-services           NaN   \n",
      "7  united states      NaN      althoff-lawn-service  construction   \n",
      "\n",
      "                                    linkedin_url   locality  \\\n",
      "0             linkedin.com/company/bedrock-black       lehi   \n",
      "2           linkedin.com/company/wh-construction      canby   \n",
      "4         linkedin.com/company/gregory-hitchcock   new york   \n",
      "5  linkedin.com/company/mission-imaging-services      arden   \n",
      "7      linkedin.com/company/althoff-lawn-service  watertown   \n",
      "\n",
      "                        name          region   size           website  \n",
      "0              bedrock black            utah   1-10  bedrockblack.com  \n",
      "2  ward-henshaw construction          oregon  11-50  ward-henshaw.com  \n",
      "4          gregory hitchcock        new york  11-50               NaN  \n",
      "5   mission imaging services  north carolina   1-10               NaN  \n",
      "7       althoff lawn service    south dakota  11-50               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Drop rows where any of the specified columns contain null values\n",
    "df = df.dropna(subset=['locality', 'region', 'name'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   founded      industry                                   linkedin_url  \\\n",
      "0   2023.0           NaN             linkedin.com/company/bedrock-black   \n",
      "2   1977.0  construction           linkedin.com/company/wh-construction   \n",
      "4      NaN  construction         linkedin.com/company/gregory-hitchcock   \n",
      "5      NaN           NaN  linkedin.com/company/mission-imaging-services   \n",
      "7      NaN  construction      linkedin.com/company/althoff-lawn-service   \n",
      "\n",
      "        city                       name           state   size  \\\n",
      "0       lehi              bedrock black            utah   1-10   \n",
      "2      canby  ward-henshaw construction          oregon  11-50   \n",
      "4   new york          gregory hitchcock        new york  11-50   \n",
      "5      arden   mission imaging services  north carolina   1-10   \n",
      "7  watertown       althoff lawn service    south dakota  11-50   \n",
      "\n",
      "            website  \n",
      "0  bedrockblack.com  \n",
      "2  ward-henshaw.com  \n",
      "4               NaN  \n",
      "5               NaN  \n",
      "7               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Remove the columns 'id' and 'country'\n",
    "df = df.drop(columns=['id', 'country'])\n",
    "\n",
    "# Rename the columns 'locality' to 'city' and 'region' to 'state'\n",
    "df.rename(columns={'locality': 'city', 'region': 'state'}, inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name       city           state  founded  \\\n",
      "0              bedrock black       lehi            utah   2023.0   \n",
      "2  ward-henshaw construction      canby          oregon   1977.0   \n",
      "4          gregory hitchcock   new york        new york      NaN   \n",
      "5   mission imaging services      arden  north carolina      NaN   \n",
      "7       althoff lawn service  watertown    south dakota      NaN   \n",
      "\n",
      "       industry                                   linkedin_url   size  \\\n",
      "0           NaN             linkedin.com/company/bedrock-black   1-10   \n",
      "2  construction           linkedin.com/company/wh-construction  11-50   \n",
      "4  construction         linkedin.com/company/gregory-hitchcock  11-50   \n",
      "5           NaN  linkedin.com/company/mission-imaging-services   1-10   \n",
      "7  construction      linkedin.com/company/althoff-lawn-service  11-50   \n",
      "\n",
      "            website  \n",
      "0  bedrockblack.com  \n",
      "2  ward-henshaw.com  \n",
      "4               NaN  \n",
      "5               NaN  \n",
      "7               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Reorder the columns so that 'name', 'city', and 'state' are the first three\n",
    "columns_order = ['name', 'city', 'state'] + [col for col in df.columns if col not in ['name', 'city', 'state']]\n",
    "df = df[columns_order]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name       city           state  founded  \\\n",
      "0              bedrock black       lehi            utah   2023.0   \n",
      "2  ward-henshaw construction      canby          oregon   1977.0   \n",
      "4          gregory hitchcock   new york        new york      NaN   \n",
      "5   mission imaging services      arden  north carolina      NaN   \n",
      "7       althoff lawn service  watertown    south dakota      NaN   \n",
      "\n",
      "       industry                                   linkedin_url   size  \\\n",
      "0           NaN             linkedin.com/company/bedrock-black   1-10   \n",
      "2  construction           linkedin.com/company/wh-construction  11-50   \n",
      "4  construction         linkedin.com/company/gregory-hitchcock  11-50   \n",
      "5           NaN  linkedin.com/company/mission-imaging-services   1-10   \n",
      "7  construction      linkedin.com/company/althoff-lawn-service  11-50   \n",
      "\n",
      "            website  \n",
      "0  bedrockblack.com  \n",
      "2  ward-henshaw.com  \n",
      "4               NaN  \n",
      "5               NaN  \n",
      "7               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'city' and 'state' columns to lowercase\n",
    "df['city'] = df['city'].str.lower()\n",
    "df['state'] = df['state'].str.lower()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name       city           state  founded  \\\n",
      "0              bedrock black       lehi            utah   2023.0   \n",
      "2  ward-henshaw construction      canby          oregon   1977.0   \n",
      "4          gregory hitchcock   new york        new york      NaN   \n",
      "5   mission imaging services      arden  north carolina      NaN   \n",
      "7       althoff lawn service  watertown    south dakota      NaN   \n",
      "\n",
      "       industry                                   linkedin_url   size  \\\n",
      "0           NaN             linkedin.com/company/bedrock-black   1-10   \n",
      "2  construction           linkedin.com/company/wh-construction  11-50   \n",
      "4  construction         linkedin.com/company/gregory-hitchcock  11-50   \n",
      "5           NaN  linkedin.com/company/mission-imaging-services   1-10   \n",
      "7  construction      linkedin.com/company/althoff-lawn-service  11-50   \n",
      "\n",
      "            website  \n",
      "0  bedrockblack.com  \n",
      "2  ward-henshaw.com  \n",
      "4               NaN  \n",
      "5               NaN  \n",
      "7               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Full names mapping (Only full names are used here)\n",
    "valid_states = {\n",
    "    'alabama', 'alaska', 'arizona', 'arkansas', 'california',\n",
    "    'colorado', 'connecticut', 'delaware', 'district of columbia', 'florida', 'georgia',\n",
    "    'hawaii', 'idaho', 'illinois', 'indiana', 'iowa',\n",
    "    'kansas', 'kentucky', 'louisiana', 'maine', 'maryland',\n",
    "    'massachusetts', 'michigan', 'minnesota', 'mississippi',\n",
    "    'missouri', 'montana', 'nebraska', 'nevada', 'new hampshire',\n",
    "    'new jersey', 'new mexico', 'new york', 'north carolina',\n",
    "    'north dakota', 'ohio', 'oklahoma', 'oregon', 'pennsylvania',\n",
    "    'rhode island', 'south carolina', 'south dakota', 'tennessee',\n",
    "    'texas', 'utah', 'vermont', 'virginia', 'washington',\n",
    "    'west virginia', 'wisconsin', 'wyoming'\n",
    "}\n",
    "\n",
    "# Filter the DataFrame to include only rows where the state is in the set of valid states\n",
    "df = df[df['state'].isin(valid_states)]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert \"saint \" to \"st. \" in city names\n",
    "def convert_saint_to_st(city_name):\n",
    "    if isinstance(city_name, str):\n",
    "        # Replace \"saint \" with \"st. \" (case-sensitive)\n",
    "        return city_name.replace(\"saint \", \"st. \")\n",
    "    return city_name\n",
    "\n",
    "# Apply the function to the 'city' column\n",
    "df['city'] = df['city'].apply(convert_saint_to_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name       city           state  founded  \\\n",
      "0              bedrock black       lehi            utah     2023   \n",
      "2  ward-henshaw construction      canby          oregon     1977   \n",
      "4          gregory hitchcock   new york        new york     <NA>   \n",
      "5   mission imaging services      arden  north carolina     <NA>   \n",
      "7       althoff lawn service  watertown    south dakota     <NA>   \n",
      "\n",
      "       industry                                   linkedin_url   size  \\\n",
      "0           NaN             linkedin.com/company/bedrock-black   1-10   \n",
      "2  construction           linkedin.com/company/wh-construction  11-50   \n",
      "4  construction         linkedin.com/company/gregory-hitchcock  11-50   \n",
      "5           NaN  linkedin.com/company/mission-imaging-services   1-10   \n",
      "7  construction      linkedin.com/company/althoff-lawn-service  11-50   \n",
      "\n",
      "            website  \n",
      "0  bedrockblack.com  \n",
      "2  ward-henshaw.com  \n",
      "4               NaN  \n",
      "5               NaN  \n",
      "7               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where 'name' is not a string or is NaN\n",
    "# Keep only rows where 'name' is a string and is not NaN\n",
    "df = df[df['name'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Function to clean company names\n",
    "def clean_company_name(name):\n",
    "    # Remove commas\n",
    "    name = name.replace(',', '')\n",
    "    # Define a regular expression pattern to match unwanted suffixes\n",
    "    pattern = (\n",
    "            r'(\\AThe\\s+|'  # Match 'The' at the start of the string\n",
    "            r'\\s+(Inc\\.?|L\\.?L\\.?C\\.?|LP|PLLC|L\\.P\\.?|P\\.C\\.?|Ltd\\.?|Co.|Corp\\.?|Intl\\.?|D\\.?D\\.?S\\.?|llp|pc)\\b|'\n",
    "            r'\\s+(holdings|holding|u\\.s\\.a|company|group|international|Corporation|&|incorporated|Co\\.?)\\s*$)'  # Match these at the end of the string\n",
    "        )\n",
    "    # Replace the matched patterns with an empty string\n",
    "    name = re.sub(pattern, '', name, flags=re.IGNORECASE)\n",
    "    # Remove any trailing periods\n",
    "    name = re.sub(r'\\.\\s*$', '', name)\n",
    "    return name.strip()\n",
    "\n",
    "# Apply the cleaning function to the 'name' column\n",
    "df['name'] = df['name'].apply(clean_company_name)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows based on the combination of 'name', 'city', and 'state'\n",
    "# keep='first' argument specifies that the first occurrence is kept, others are deleted\n",
    "df_cleaned = df.drop_duplicates(subset=['name', 'city', 'state'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'founded' column to integers, coercing errors to NaN\n",
    "# This step will convert non-numeric values to NaN and leave existing NaN values as they are\n",
    "df['founded'] = pd.to_numeric(df['founded'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to a new CSV file\n",
    "df.to_csv('clean-companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name, city, state, founded, industry, linkedin_url, size, website, city_id]\n",
      "Index: []\n",
      "                        name       city           state  founded  \\\n",
      "0              bedrock black       lehi            utah   2023.0   \n",
      "1  ward-henshaw construction      canby          oregon   1977.0   \n",
      "2          gregory hitchcock   new york        new york      NaN   \n",
      "3   mission imaging services      arden  north carolina      NaN   \n",
      "4       althoff lawn service  watertown    south dakota      NaN   \n",
      "\n",
      "       industry                                   linkedin_url   size  \\\n",
      "0           NaN             linkedin.com/company/bedrock-black   1-10   \n",
      "1  construction           linkedin.com/company/wh-construction  11-50   \n",
      "2  construction         linkedin.com/company/gregory-hitchcock  11-50   \n",
      "3           NaN  linkedin.com/company/mission-imaging-services   1-10   \n",
      "4  construction      linkedin.com/company/althoff-lawn-service  11-50   \n",
      "\n",
      "            website  city_id  \n",
      "0  bedrockblack.com    30836  \n",
      "1  ward-henshaw.com    24894  \n",
      "2               NaN    20587  \n",
      "3               NaN    21607  \n",
      "4               NaN    28319  \n"
     ]
    }
   ],
   "source": [
    "# Generate csv to import into company table in database\n",
    "\n",
    "# Load the cost of living data\n",
    "companies_df = pd.read_csv(\"clean-companies.csv\")\n",
    "\n",
    "# Load city data\n",
    "city_df = pd.read_csv(\"city-table.csv\")\n",
    "city_df.rename(columns={'id': 'city_id'}, inplace=True)\n",
    "\n",
    "# Merge the DataFrames to map city_id based on city and state\n",
    "merged_df = pd.merge(companies_df, city_df, on=['city', 'state'], how='left')  \n",
    "\n",
    "# Check for any entries that did not get a city_id (these will need to be addressed)\n",
    "print(merged_df[merged_df['city_id'].isnull()])\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name       city           state  founded  \\\n",
      "0              bedrock black       lehi            utah     2023   \n",
      "1  ward-henshaw construction      canby          oregon     1977   \n",
      "2          gregory hitchcock   new york        new york     <NA>   \n",
      "3   mission imaging services      arden  north carolina     <NA>   \n",
      "4       althoff lawn service  watertown    south dakota     <NA>   \n",
      "\n",
      "       industry                                   linkedin_url   size  \\\n",
      "0           NaN             linkedin.com/company/bedrock-black   1-10   \n",
      "1  construction           linkedin.com/company/wh-construction  11-50   \n",
      "2  construction         linkedin.com/company/gregory-hitchcock  11-50   \n",
      "3           NaN  linkedin.com/company/mission-imaging-services   1-10   \n",
      "4  construction      linkedin.com/company/althoff-lawn-service  11-50   \n",
      "\n",
      "            website  city_id  \n",
      "0  bedrockblack.com    30836  \n",
      "1  ward-henshaw.com    24894  \n",
      "2               NaN    20587  \n",
      "3               NaN    21607  \n",
      "4               NaN    28319  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'founded' column to integers, coercing errors to NaN\n",
    "# This step will convert non-numeric values to NaN and leave existing NaN values as they are\n",
    "merged_df['founded'] = pd.to_numeric(merged_df['founded'], errors='coerce').astype('Int64')\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   city_id                       name       city           state  founded  \\\n",
      "0    30836              bedrock black       lehi            utah     2023   \n",
      "1    24894  ward-henshaw construction      canby          oregon     1977   \n",
      "2    20587          gregory hitchcock   new york        new york     <NA>   \n",
      "3    21607   mission imaging services      arden  north carolina     <NA>   \n",
      "4    28319       althoff lawn service  watertown    south dakota     <NA>   \n",
      "\n",
      "       industry                                   linkedin_url   size  \\\n",
      "0           NaN             linkedin.com/company/bedrock-black   1-10   \n",
      "1  construction           linkedin.com/company/wh-construction  11-50   \n",
      "2  construction         linkedin.com/company/gregory-hitchcock  11-50   \n",
      "3           NaN  linkedin.com/company/mission-imaging-services   1-10   \n",
      "4  construction      linkedin.com/company/althoff-lawn-service  11-50   \n",
      "\n",
      "            website  \n",
      "0  bedrockblack.com  \n",
      "1  ward-henshaw.com  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Reorder columns to make 'city_id' the first column\n",
    "# Get a list of all columns, then filter out 'city_id'\n",
    "cols = merged_df.columns.tolist()\n",
    "cols = ['city_id'] + [col for col in cols if col != 'city_id']\n",
    "\n",
    "# Reassign reordered columns back to the DataFrame\n",
    "merged_df = merged_df[cols]\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   city_id                       name  founded      industry  \\\n",
      "0    30836              bedrock black     2023           NaN   \n",
      "1    24894  ward-henshaw construction     1977  construction   \n",
      "2    20587          gregory hitchcock     <NA>  construction   \n",
      "3    21607   mission imaging services     <NA>           NaN   \n",
      "4    28319       althoff lawn service     <NA>  construction   \n",
      "\n",
      "                                    linkedin_url   size           website  \n",
      "0             linkedin.com/company/bedrock-black   1-10  bedrockblack.com  \n",
      "1           linkedin.com/company/wh-construction  11-50  ward-henshaw.com  \n",
      "2         linkedin.com/company/gregory-hitchcock  11-50               NaN  \n",
      "3  linkedin.com/company/mission-imaging-services   1-10               NaN  \n",
      "4      linkedin.com/company/althoff-lawn-service  11-50               NaN  \n"
     ]
    }
   ],
   "source": [
    "# Drop the city and state columns as they are no longer needed\n",
    "merged_df.drop(columns=['city', 'state'], inplace=True)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file, ready for database import\n",
    "merged_df.to_csv('importable-companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 5920475\n",
      "Number of rows after removing nulls in 'name': 5920472\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('importable-companies.csv')\n",
    "\n",
    "# Print the number of rows before removal\n",
    "original_row_count = df.shape[0]\n",
    "print(\"Original number of rows:\", original_row_count)\n",
    "\n",
    "# Remove rows where the 'name' column is null\n",
    "df_cleaned = df.dropna(subset=['name'])\n",
    "\n",
    "# Print the number of rows after removal\n",
    "updated_row_count = df_cleaned.shape[0]\n",
    "print(\"Number of rows after removing nulls in 'name':\", updated_row_count)\n",
    "\n",
    "df_cleaned.to_csv('importable-companies.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
